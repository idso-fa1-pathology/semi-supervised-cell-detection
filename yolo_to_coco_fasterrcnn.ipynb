{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def convert_bbox_from_normalized_to_coco(x_center, y_center, width, height, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert bounding box from normalized coordinates (center x, center y, width, height)\n",
    "    to COCO format (top left x, top left y, width, height) in absolute coordinates.\n",
    "    \"\"\"\n",
    "    x_center *= img_width\n",
    "    y_center *= img_height\n",
    "    width *= img_width\n",
    "    height *= img_height\n",
    "\n",
    "    top_left_x = x_center - (width / 2)\n",
    "    top_left_y = y_center - (height / 2)\n",
    "\n",
    "    return [top_left_x, top_left_y, width, height]\n",
    "\n",
    "def create_coco_json(annotations_dir, img_dim):\n",
    "    \"\"\"\n",
    "    Creates a COCO formatted JSON file from the given annotations directory.\n",
    "    \"\"\"\n",
    "    # COCO dataset structure\n",
    "    coco_dataset = {\n",
    "        \"info\": {},  # Can be filled with dataset information\n",
    "        \"licenses\": [],  # Can be filled with license information\n",
    "        \"categories\": [{\"id\": 0, \"name\": \"class_0\"}, {\"id\": 1, \"name\": \"class_1\"}, {\"id\": 2, \"name\": \"class_2\"}],\n",
    "        \"images\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "\n",
    "    # Variables to assign unique IDs to each image and annotation\n",
    "    image_id = 1\n",
    "    annotation_id = 1\n",
    "\n",
    "    # Iterate over annotation files in the directory\n",
    "    for ann_file in glob.glob(os.path.join(annotations_dir, '*.txt')):\n",
    "        # Corresponding image file\n",
    "        img_file = ann_file.replace('.txt', '.jpg')\n",
    "\n",
    "        # Add image information to the dataset\n",
    "        coco_dataset['images'].append({\n",
    "            \"id\": image_id,\n",
    "            \"file_name\": os.path.basename(img_file),\n",
    "            \"width\": img_dim,\n",
    "            \"height\": img_dim\n",
    "        })\n",
    "\n",
    "        # Read and process each annotation in the file\n",
    "        with open(ann_file, 'r') as file:\n",
    "            for line in file:\n",
    "                class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                bbox = convert_bbox_from_normalized_to_coco(x_center, y_center, width, height, img_dim, img_dim)\n",
    "\n",
    "                # Add annotation information to the dataset\n",
    "                coco_dataset['annotations'].append({\n",
    "                    \"id\": annotation_id,\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": int(class_id),\n",
    "                    \"bbox\": bbox,\n",
    "                    \"area\": bbox[2] * bbox[3],  # width * height\n",
    "                    \"segmentation\": [],  # This can be filled if segmentation info is available\n",
    "                    \"iscrowd\": 0\n",
    "                })\n",
    "\n",
    "                annotation_id += 1\n",
    "\n",
    "        image_id += 1\n",
    "\n",
    "    return coco_dataset\n",
    "\n",
    "# Path to the annotations directory\n",
    "annotations_dir = '/Users/yshokrollahi/Desktop/MD/Project3/dataset/IF/ROIs/full_PA/all_aug/final/test/labels'\n",
    "\n",
    "# Image dimension (assuming square images)\n",
    "img_dim = 640\n",
    "\n",
    "# Generate COCO JSON\n",
    "coco_json = create_coco_json(annotations_dir, img_dim)\n",
    "\n",
    "# This is an example script, so we won't actually write the file here.\n",
    "# In practice, you would save `coco_json` to a file using json.dump().\n",
    "\n",
    "import json\n",
    "\n",
    "def save_coco_json(coco_data, output_file_path):\n",
    "    \"\"\"\n",
    "    Saves the COCO data to a JSON file.\n",
    "\n",
    "    :param coco_data: The COCO data to be saved.\n",
    "    :param output_file_path: The file path where the COCO JSON should be saved.\n",
    "    \"\"\"\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        json.dump(coco_data, file, indent=4)\n",
    "\n",
    "# Example usage:\n",
    "output_file_path = '/Users/yshokrollahi/Desktop/MD/Project3/dataset/IF/ROIs/full_PA/all_aug/final/test/coco_file.json'  # Replace with your actual file path\n",
    "save_coco_json(coco_json, output_file_path)\n",
    "print(\"Done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randmoly delete annotaion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Define the source and target directories\n",
    "source_dir = '/Users/yshokrollahi/Desktop/MD/Project3/dataset/IF/ROIs/full_PA/all_aug/final/valid/labels'\n",
    "target_dir = '/Users/yshokrollahi/Desktop/MD/Project3/dataset/IF/ROIs/full_PA/all_aug/final_25/valid/labels'\n",
    "\n",
    "# Create the target directory if it does not exist\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "# Process each file in the source directory\n",
    "for filename in os.listdir(source_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(source_dir, filename)\n",
    "\n",
    "        # Read lines from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Randomly delete 50% of the lines\n",
    "        lines_to_keep = random.sample(lines, k=len(lines) // 4)\n",
    "\n",
    "        # Write the remaining lines to a new file in the target directory\n",
    "        target_file_path = os.path.join(target_dir, filename)\n",
    "        with open(target_file_path, 'w') as file:\n",
    "            file.writelines(lines_to_keep)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2963791,
     "sourceId": 5103563,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30407,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
